{
  "Objects": [
    {
      "name": "mlmat.convert",
      "description": "Convert matrices between mlmat modes. Converts a matrix to between different mlmat modes. <at>input</at> specifies the expected input mode and <at>output</at> indicates the mode to convert to. Note that this will fail if attempting to convert from mode 1 or 2 to mode 0 if the resulting matrix would require more than 32 planes.",
      "related": "mlmat.scaling, mlmat.lookup",
      "discussion": "",
      "attributes": [
        {
          "name": "input",
          "description": ""
        },
        {
          "name": "output",
          "description": ""
        }
      ],
      "messages": [
        {
          "name": "",
          "description": ""
        }
      ]
    },
    {
      "name": "mlmat.gmm",
      "description": "A Gaussian Mixture Model. A Gaussian Mixture Model takes a parametric estimate of a Gaussian mixture model (GMM) using the EM algorithm to find the maximum likelihood estimate.",
      "related": "mlpack.knn, mlpack.hmm, mlpack.linear_svm",
      "discussion": "In addition to being able to determine the probability that input comes from the learned distribution, this object has a number of features for generating data based ont the learned model. The <at>generate</at> message can be used to create N number of randomly generated observations based on the model. The <at>component</at> message can be used to generate N observations from a single component of the model. The <at>weights message can be used to alter the relative weights of the components when generating random observations using the <at>weighted_generate</at> message.",
      "attributes": [
        {
          "name": "autoclear",
          "description": "Clear training data from memory after the model has been trained."
        },
        {
          "name": "gaussians",
          "description": "Number of Gaussians in the GMM."
        },
        {
          "name": "seed",
          "description": "Random seed. 0 indicates no seed"
        },
        {
          "name": "trials",
          "description": "Number of trials to perform in training GMM."
        },
        {
          "name": "diagonal_covariance",
          "description": "Force the covariance of the Gaussians to be diagonal.  This can accelerate training time significantly."
        },
        {
          "name": "classify",
          "description": "Classify the given observations as being from an individual component in this GMM. This will output a matrix out fourth outlet."
        },
        {
          "name": "noise",
          "description": "Variance of zero-mean Gaussian noise to add to data."
        },
        {
          "name": "kmeans_max_iterations",
          "description": "Maximum number of iterations for the k-means algorithm (used to initialize EM)."
        },
        {
          "name": "max_iterations",
          "description": "Maximum number of iterations of EM algorithm (passing 0 will run until convergence)."
        },
        {
          "name": "refined_start",
          "description": "During the initialization, use refined initial positions for k-means clustering. "
        },
        {
          "name": "no_force_positive",
          "description": "Do not force the covariance matrices to be positive definite. Recommend leaving this as false."
        },
        {
          "name": "samplings",
          "description": "If using refined_start, specify the number of samplings used for initial points."
        },
        {
          "name": "tolerance",
          "description": "Tolerance for convergence of EM."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "weights",
          "description": "Weights for gaussians when using <at>weighted_generate</at>"
        },
        {
          "name": "train",
          "description": "Train model."
        },
        {
          "name": "weighted_generate",
          "description": "Generate points based on distribution and weighted by <at>weights</at>."
        },
        {
          "name": "generate",
          "description": "Generate points based on distribution."
        },
        {
          "name": "component",
          "description": "Generate points using specified component of the GMM."
        }
      ]
    },
    {
      "name": "mlmat.hmm",
      "description": "Hidden Markov Model. An implementation Hidden Markov Model (HMM). The model can be based on one of four basic types set by <at>hmm_type</at>.",
      "related": "mlpack.gmm",
      "discussion": "",
      "attributes": [
        {
          "name": "autoclear",
          "description": "Clear training data from memory after the model has been trained."
        },
        {
          "name": "use_labels",
          "description": "Use labels in training phase. The labels must match the number of training samples. Labels must be used when using <at>hmm_type</at> diag_gmm or gmm."
        },
        {
          "name": "states",
          "description": "Number of hidden states in HMM"
        },
        {
          "name": "gaussians",
          "description": "Number of gaussians in each GMM (necessary when type is 'gmm'."
        },
        {
          "name": "seed",
          "description": "Random seed. 0 indicates no seed."
        },
        {
          "name": "tolerance",
          "description": "Tolerance of the Baum-Welch algorithm."
        },
        {
          "name": "hmm_type",
          "description": "Type of HMM"
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "",
          "description": ""
        }
      ]
    },
    {
      "name": "mlmat.hoeffding_tree",
      "description": "Hoeffding Decision Tree. An implementation of Hoeffding trees, a form of streaming decision tree for classification. Given labeled data, a Hoeffding tree can be trained and saved for later use, or a pre-trained Hoeffding tree can be used for predicting the classifications of new points.",
      "related": "mlpack.id3_tree",
      "discussion": "The Hoeffding tree is well suited for incremental learning meaning that rather than provide all the data at once it will refine the decision tree as it receives more data. However, it can be used as a traditional decision tree if the <at>batch_mode</at> attribute is set to 1.",
      "attributes": [
        {
          "name": "batch_mode",
          "description": "The training may be performed in batch mode (like a typical decision tree algorithm) by specifying the option, but this may not be the best option for large datasets."
        },
        {
          "name": "confidence",
          "description": "Confidence before splitting (between 0 and 1)."
        },
        {
          "name": "max_samples",
          "description": "Maximum number of samples before splitting."
        },
        {
          "name": "check_interval",
          "description": "Number of samples required before each split check."
        },
        {
          "name": "min_samples",
          "description": "Minimum number of samples before splitting."
        },
        {
          "name": "split_strategy",
          "description": "The splitting strategy to use for numeric features."
        },
        {
          "name": "info_gain",
          "description": "If set, information gain is used instead of Gini impurity for calculating Hoeffding bounds."
        },
        {
          "name": "passes",
          "description": "Number of passes to take over the dataset."
        },
        {
          "name": "bins",
          "description": "If the 'domingos' split strategy is used by <at>split_strategy</at>, this specifies the number of bins for each numeric split."
        },
        {
          "name": "observations_before_binning",
          "description": "If the 'domingos' split strategy is used by <at>split_strategy</at>, this specifies the number of samples observed before binning is performed."
        },
        {
          "name": "reset_tree",
          "description": "If true, reset the tree to an empty tree before training."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model."
        }
      ]
    },
    {
      "name": "mlmat.id3_tree",
      "description": "ID3 Decision Tree Classifier.",
      "related": "mlpack.hoeffding_tree",
      "discussion": "This is a robust decision tree algorithm that works with labeled data. It is useful to experiment with <at>minimum_leaf_size</at> and <at>minimum_gain_split</at> to get a good decision tree.",
      "attributes": [
        {
          "name": "minimum_leaf_size",
          "description": "Minimum leaf size for tree. "
        },
        {
          "name": "minimum_gain_split",
          "description": "Minimum gain for node splitting."
        },
        {
          "name": "maximum_depth",
          "description": "Maximum depth of the tree.(0 means no limit)."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model"
        }
      ]
    },
    {
      "name": "mlmat.kfn",
      "description": "K-farthest neighbor search. An implementation of k-farthest-neighbor search using single-tree and dual-tree algorithms. Given a set of reference points and query points, this can find the k furthest neighbors in the reference set of each query point using trees; trees that are built can be saved for future use.",
      "related": "mlpack.knn",
      "discussion": "",
      "attributes": [
        {
          "name": "neighbors",
          "description": "Number of neighbors to query."
        },
        {
          "name": "epsilon",
          "description": "If specified, will search with given relative error."
        },
        {
          "name": "tree_type",
          "description": "Type of tree to use"
        },
        {
          "name": "algorithm",
          "description": "Type of neighbor search"
        },
        {
          "name": "leaf_size",
          "description": "Leaf size for tree building (used for kd-trees, vp trees, random projection trees, UB trees, R trees, R* trees, X trees, Hilbert R trees, R+ trees, R++ trees, spill trees, and octrees)."
        },
        {
          "name": "percentage",
          "description": "Resultant neighbors will be at least (p*100) % of the distance as the true furthest neighbor Range 0 to 1."
        },
        {
          "name": "random_basis",
          "description": "Before tree-building, project the data onto a random orthogonal basis."
        },
        {
          "name": "seed",
          "description": "Random seed if random basis being used. 0 indicates no seed."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": []
    },
    {
      "name": "mlmat.kmeans",
      "description": "K means clustering. An implementation of several strategies for efficient k-means clustering. Given a dataset and a value of k, this computes and returns a k-means.",
      "related": "mlpack.knn, mlpack.kfn",
      "discussion": "",
      "attributes": [
        {
          "name": "clusters",
          "description": "Algorithm to use for the Lloyd iteration."
        },
        {
          "name": "max_iterations",
          "description": "Maximum number of iterations before k-means terminates."
        },
        {
          "name": "allow_empty_clusters",
          "description": "Allow empty clusters to be persist."
        },
        {
          "name": "reuse_centroids",
          "description": "Use previous calculated centroids for current clustering."
        },
        {
          "name": "reuse_assignments",
          "description": "Use previous assignments for current clustering. If both reuse_centroids and reuse_assignments are 1, reuse_assignments overrides."
        },
        {
          "name": "refined_start",
          "description": "Use refined start sampling to partition data."
        },
        {
          "name": "samplings",
          "description": "Number of samplings to perform for refined start (use when refined_start is specified)."
        },
        {
          "name": "percentage",
          "description": "Percentage of dataset to use for each refined start sampling (use when refined_start is specified)."
        },
        {
          "name": "seed",
          "description": "Random seed if random basis being used. 0 indicates no seed."
        }
      ],
      "messages": []
    },
    {
      "name": "mlmat.knn",
      "description": "K-nearest neighbor search. An implementation of k-nearest-neighbor search using single-tree and dual-tree algorithms. Given a set of reference points and query points, this can find the k nearest neighbors in the reference set of each query point using trees; trees that are built can be saved for future use.",
      "related": "mlpack.kfn",
      "discussion": "",
      "attributes": [
        {
          "name": "neighbors",
          "description": "Number of neighbors to query."
        },
        {
          "name": "epsilon",
          "description": "If specified, will search with given relative error."
        },
        {
          "name": "tree_type",
          "description": "Type of tree to use."
        },
        {
          "name": "algorithm",
          "description": "Type of neighbor search."
        },
        {
          "name": "leaf_size",
          "description": "Leaf size for tree building (used for kd-trees, vp trees, random projection trees, UB trees, R trees, R* trees, X trees, Hilbert R trees, R+ trees, R++ trees, spill trees, and octrees)."
        },
		{
          "name": "tau",
          "description": "Overlapping size (only valid for spill trees). Must be positive."
        },
        {
          "name": "rho",
          "description": "Balance threshold (only valid for spill trees). Range 0 to 1."
        },
        {
          "name": "random_basis",
          "description": "Before tree-building, project the data onto a random orthogonal basis."
        },
        {
          "name": "seed",
          "description": "Random seed if random basis being used. 0 indicates no seed."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": []
    
    },
    {
      "name": "mlmat.linear_regression",
      "description": "A Linear Regression Model. An implementation of simple linear regression and ridge regression using ordinary least squares. Given a dataset and responses, a model can be trained and saved for later use, or a pre-trained model can be used to output regression predictions for a test set.",
      "related": "mlpack.gmm",
      "discussion": "",
      "attributes": [
        {
          "name": "lambda",
          "description": "Tikhonov regularization for ridge regression. If 0, the method reduces to linear regression."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model."
        },
         {
          "name": "getparameters",
          "description": "Outputs the parameters (the b vector) via dump outlet."
        }
      ]
    },
    {
      "name": "mlmat.linear_svm",
      "description": "Linear SVM. An implementation of linear SVM for multiclass classification. Given labeled data, a model can be trained and saved for future use; or, a pre-trained model can be used to classify new points.",
      "related": "mlmat.linear_regression, mlmat.mlp_classifier",
      "discussion": "",
      "attributes": [
        {
          "name": "lambda",
          "description": "lambda"
        },
        {
          "name": "delta",
          "description": "Margin of difference between correct class and other classes."
        },
        {
          "name": "num_classes",
          "description": "Margin of difference between correct class and other classes."
        },
        {
          "name": "no_intercept",
          "description": "Do not add the intercept term to the model."
        },
        {
          "name": "optimizer",
          "description": "Optimizer to use for training."
        },
        {
          "name": "tolerance",
          "description": "Convergence tolerance for optimizer."
        },
        {
          "name": "max_iterations",
          "description": "Maximum iterations for optimizer (0 indicates no limit)."
        },
        {
          "name": "step_size",
          "description": "Step size for parallel SGD optimizer."
        },
        {
          "name": "shuffle",
          "description": "Shuffle the order in which data points are visited for parallel SGD."
        },
        {
          "name": "epochs",
          "description": "Maximum number of full epochs over dataset for psgd."
        },
        {
          "name": "seed",
          "description": "Random seed if random basis being used. 0 indicates no seed."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model"
        }
      ]
    },
    {
      "name": "mlmat.load",
      "description": "Load data from file. Currently only supports numeric data.",
      "related": "",
      "discussion": "There are a number of file formats supported. These include:\n       csv (comma-separated values), denoted by .csv or .txt\ntsv (tab-separated values), denoted by .tsv, .csv, or .txt\nASCII (raw ASCII, with space-separated values), denoted by .txt\nArmadillo ASCII (Armadillo's text format with a header), denoted by .txt\nPGM, denoted by .pgm\nPPM, denoted by .ppm\nArmadillo binary, denoted by .bin\nRaw binary, denoted by .bin (note: this will be loaded as one-dimensional data, which is likely not what is desired.)\nARFF, denoted by .arff\n",
      "attributes": [
        {
          "name": "transpose",
          "description": "If true, transpose the matrix after loading. This is normally the desired behavior"
        }
      ],
      "messages": [
        {
          "name": "read",
          "description": "data file to read"
        }
      ]
    },
    {
      "name": "mlmat.lookup",
      "description": "Utility for getting indexed data from a matrix.",
      "related": "",
      "discussion": "",
      "attributes": [],
      "messages": []
    },
    {
      "name": "mlmat.mean_shift",
      "description": "Mean-shift clustering. A fast implementation of mean-shift clustering using dual-tree range search. Given a dataset, this uses the mean shift algorithm to produce and return a clustering of the data.",
      "related": "",
      "discussion": "",
      "attributes": [
        {
          "name": "max_iterations",
          "description": "Maximum number of iterations before k-means terminates."
        },
        {
          "name": "radius",
          "description": "If the distance between two centroids is less than the given radius, one will be removed.  A radius of 0 or less means an estimate will be calculated and used for the radius."
        },
        {
          "name": "force_convergence",
          "description": "If specified, the mean shift algorithm will continue running regardless of max_iterations until the clusters converge."
        }
      ],
      "messages": [
        {
          "name": "",
          "description": ""
        }
      ]
    },
    {
      "name": "mlmat.mlp_classifier",
      "description": "Multi layer perceptron. This mlp can be used as a classifier.",
      "related": "mlpack.svm",
      "discussion": "",
      "attributes": [
        {
          "name": "output_neurons",
          "description": "Number of output neurons."
        },
        {
          "name": "hidden_layers",
          "description": "Number of hidden layers."
        },
        {
          "name": "hidden_neurons",
          "description": "Number of neurons for each hidden layer."
        },
        {
          "name": "activation",
          "description": "The activation function to use in the hidden layers."
        },
        {
          "name": "optimizer",
          "description": "The optimizer to use."
        },
        {
          "name": "step_size",
          "description": "Step size for parallel SGD optimizer."
        },
        {
          "name": "batch_size",
          "description": "Batch size for mini-batch SGD."
        },
        {
          "name": "max_iterations",
          "description": "Maximum iterations for optimizer (0 indicates no limit)."
        },
        {
          "name": "tolerance",
          "description": "Convergence tolerance for optimizer."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model."
        }
      ]
    },
    {
      "name": "mlmat.mlp_regressor",
      "description": "Multi layer perceptron. This mlp can be used as a regressor.",
      "related": "mlpack.linear_regression",
      "discussion": "",
      "attributes": [
        {
          "name": "hidden_layers",
          "description": "Number of hidden layers."
        },
        {
          "name": "hidden_neurons",
          "description": "Number of neurons for each hidden layer."
        },
        {
          "name": "activation",
          "description": "The activation function to use in the hidden layers."
        },
        {
          "name": "optimizer",
          "description": "The optimizer to use."
        },
        {
          "name": "step_size",
          "description": "Step size for parallel SGD optimizer."
        },
        {
          "name": "batch_size",
          "description": "Batch size for mini-batch SGD."
        },
        {
          "name": "max_iterations",
          "description": "Maximum iterations for optimizer (0 indicates no limit)."
        },
        {
          "name": "tolerance",
          "description": "Convergence tolerance for optimizer."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model."
        }
      ]
    },
    {
      "name": "mlmat.pca",
      "description": "Principal Components Analysis. An implementation of several strategies for principal components analysis (PCA), a common preprocessing step.  Given a dataset and a desired new dimensionality, this can reduce the dimensionality of the data using the linear transformation determined by PCA.",
      "related": "mlpack.linear_regression",
      "discussion": "",
      "attributes": [
        {
          "name": "new_dimensionality",
          "description": "Desired dimensionality obf output dataset. If 0, no dimensionality reduction is performed."
        },
        {
          "name": "scale",
          "description": "If set, the data will be scaled before running PCA, such that the variance of each feature is 1."
        },
        {
          "name": "decomposition_method",
          "description": "Method used for the principal components analysis."
        },
        {
          "name": "seed",
          "description": "Random seed if random basis being used. 0 indicates no seed."
        }
      ]
    },
    {
      "name": "mlmat.scaling",
      "description": "Apply various scaling strategies. This will apply different type of scaling to datasets. Further data can be scaled using the fitting of original dataset. Inverse transform can also be applied.",
      "related": "mlpack.id3_tree",
      "discussion": "",
      "attributes": [
        {
          "name": "scaler",
          "description": "The scaler type."
        },
        {
          "name": "min",
          "description": "Minimum value when using the min_max scaler."
        },
        {
          "name": "max",
          "description": "Maximum value when using the min_max scaler."
        },
        {
          "name": "epsilon",
          "description": "Regularization parameter for pca_whitening and zca_whitening scalers."
        },
        {
          "name": "inverse",
          "description": "Apply inverse transform to matrix."
        }
      ]
    },
    {
      "name": "mlmat.som",
      "description": "Self-organizing map, This allows for the contruction of a 2D Self-organizing map",
      "related": "mlmat.kmeans, mlmat.mean_shift",
      "discussion": "",
      "attributes": [
        {
          "name": "rows",
          "description": "The number of rows in map"
        },
        {
          "name": "cols",
          "description": "The number of columns in map."
        },
        {
          "name": "epochs",
          "description": "The number of passes over training set."
        },
        {
          "name": "learning_rate",
          "description": "Learning rate when not in <at>batch_mode</at>."
        },
        {
          "name": "batch_process",
          "description": "Will use batch variant of som algorithm."
        },
        {
          "name": "initialization",
          "description": "Set how initialization of SOM is performed. uniform uses uniform random between 0-1, gaussian uses a guassian random distribution and sample will use randomly sampled values from the input matrix."
        },
        {
          "name": "neighborhood",
          "description": "Neighborhood radius. Zero means use full map radius."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model."
        }
      ]
    },
    {
      "name": "mlpack.sparse_autoencoder",
      "description": "Sparse autoencoder.",
      "related": "mlpack.id3_tree",
      "discussion": "",
      "attributes": [
        {
          "name": "hidden_size",
          "description": "Size of input vector expected at the hidden layer."
        },
        {
          "name": "lambda",
          "description": "L2-regularization parameter."
        },
        {
          "name": "beta",
          "description": "KL divergence parameter."
        },
        {
          "name": "rho",
          "description": "Sparsity parameter."
        },
        {
          "name": "file",
          "description": "File to read a pre-trained model from. "
        }
      ],
      "messages": [
        {
          "name": "train",
          "description": "Train model."
        }
      ]
    },
    {
      "name": "mlmat.split",
      "description": "Splits data into testing and training.",
      "related": "mlpack.scaling",
      "discussion": "",
      "attributes": [
        {
          "name": "use_labels",
          "description": "Random seed if random basis being used. 0 indicates no seed."
        },
        {
          "name": "ratio",
          "description": "Percentage of dataset to use for test set (between 0 and 1)."
        },
        {
          "name": "shuffle",
          "description": "If true, the sample order is shuffled; otherwise, each sample is visited in linear order.   number of samples before splitting."
        }
      ]
    }
  ]
}